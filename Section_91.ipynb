{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPw04TDvAQkrfj8cZHmg7uw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nisha1365/Udemy_Course_1-python-100-days-/blob/main/Section_91.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A website that finds the most common colours in an uploaded image."
      ],
      "metadata": {
        "id": "xQUj08kywPDh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import PIL\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "BKuccJTWwTI4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2 — Load and show sample images"
      ],
      "metadata": {
        "id": "gfrmX2-vwy5c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_img_compar(img_1, img_2 ):\n",
        "    f, ax = plt.subplots(1, 2, figsize=(10,10))\n",
        "    ax[0].imshow(img_1)\n",
        "    ax[1].imshow(img_2)\n",
        "    ax[0].axis('off') #hide the axis\n",
        "    ax[1].axis('off')\n",
        "    f.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "L-ExSUckwzM_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we’ll load some sample images that we’ll be using in this tutorial and show them using the function above."
      ],
      "metadata": {
        "id": "ju66hrr5w3XI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img = cv.imread(\"img/img_1.jpg\")\n",
        "img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
        "img_2 = cv.imread(\"img/img_2.jpg\")\n",
        "img_2 = cv.cvtColor(img_2, cv.COLOR_BGR2RGB)\n",
        "\n",
        "dim = (500, 300)\n",
        "# resize image\n",
        "img = cv.resize(img, dim, interpolation = cv.INTER_AREA)\n",
        "img_2 = cv.resize(img_2, dim, interpolation = cv.INTER_AREA)\n",
        "\n",
        "show_img_compar(img, img_2)"
      ],
      "metadata": {
        "id": "LbpjBR33w3t1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Method 1 — Average\n",
        "The first method is the easiest (but ineffective one) — simply find the average pixel values."
      ],
      "metadata": {
        "id": "naDiiS48w7cd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_temp = img.copy()\n",
        "img_temp[:,:,0], img_temp[:,:,1], img_temp[:,:,2] = np.average(img, axis=(0,1))\n",
        "\n",
        "img_temp_2 = img_2.copy()\n",
        "img_temp_2[:,:,0], img_temp_2[:,:,1], img_temp_2[:,:,2] = np.average(img_2, axis=(0,1))\n",
        "\n",
        "show_img_compar(img, img_temp)\n",
        "show_img_compar(img_2, img_temp_2)"
      ],
      "metadata": {
        "id": "dxIwl2Phw7tf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_temp = img.copy()\n",
        "unique, counts = np.unique(img_temp.reshape(-1, 3), axis=0, return_counts=True)\n",
        "img_temp[:,:,0], img_temp[:,:,1], img_temp[:,:,2] = unique[np.argmax(counts)]\n",
        "\n",
        "img_temp_2 = img_2.copy()\n",
        "unique, counts = np.unique(img_temp_2.reshape(-1, 3), axis=0, return_counts=True)\n",
        "img_temp_2[:,:,0], img_temp_2[:,:,1], img_temp_2[:,:,2] = unique[np.argmax(counts)]\n",
        "\n",
        "show_img_compar(img, img_temp)\n",
        "show_img_compar(img_2, img_temp_2)"
      ],
      "metadata": {
        "id": "swTZGnnoxBGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Method 3 — Using K-Means clustering\n",
        "Scikit-learn package comes to the rescue. We can use the infamous K-Means clustering to cluster groups of colors together"
      ],
      "metadata": {
        "id": "GqDJuCJxxD96"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def palette(clusters):\n",
        "    width=300\n",
        "    palette = np.zeros((50, width, 3), np.uint8)\n",
        "    steps = width/clusters.cluster_centers_.shape[0]\n",
        "    for idx, centers in enumerate(clusters.cluster_centers_): \n",
        "        palette[:, int(idx*steps):(int((idx+1)*steps)), :] = centers\n",
        "    return palette\n",
        "\n",
        "  \n",
        "clt_1 = clt.fit(img.reshape(-1, 3))\n",
        "show_img_compar(img, palette(clt_1))\n",
        "\n",
        "clt_2 = clt.fit(img_2.reshape(-1, 3))\n",
        "show_img_compar(img_2, palette(clt_2))"
      ],
      "metadata": {
        "id": "0zeunxCxxGi_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def palette(clusters):\n",
        "    width=300\n",
        "    palette = np.zeros((50, width, 3), np.uint8)\n",
        "    steps = width/clusters.cluster_centers_.shape[0]\n",
        "    for idx, centers in enumerate(clusters.cluster_centers_): \n",
        "        palette[:, int(idx*steps):(int((idx+1)*steps)), :] = centers\n",
        "    return palette\n",
        "\n",
        "clt_3 = KMeans(n_clusters=3)\n",
        "clt_3.fit(img_2.reshape(-1, 3))\n",
        "show_img_compar(img_2, palette(clt_3))"
      ],
      "metadata": {
        "id": "L7TFMwdZxJK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "def palette_perc(k_cluster):\n",
        "    width = 300\n",
        "    palette = np.zeros((50, width, 3), np.uint8)\n",
        "    \n",
        "    n_pixels = len(k_cluster.labels_)\n",
        "    counter = Counter(k_cluster.labels_) # count how many pixels per cluster\n",
        "    perc = {}\n",
        "    for i in counter:\n",
        "        perc[i] = np.round(counter[i]/n_pixels, 2)\n",
        "    perc = dict(sorted(perc.items()))\n",
        "    \n",
        "    #for logging purposes\n",
        "    print(perc)\n",
        "    print(k_cluster.cluster_centers_)\n",
        "    \n",
        "    step = 0\n",
        "    \n",
        "    for idx, centers in enumerate(k_cluster.cluster_centers_): \n",
        "        palette[:, step:int(step + perc[idx]*width+1), :] = centers\n",
        "        step += int(perc[idx]*width+1)\n",
        "        \n",
        "    return palette\n",
        "    \n",
        "clt_1 = clt.fit(img.reshape(-1, 3))\n",
        "show_img_compar(img, palette_perc(clt_1))\n",
        "\n",
        "clt_2 = clt.fit(img_2.reshape(-1, 3))\n",
        "show_img_compar(img_2, palette_perc(clt_2))"
      ],
      "metadata": {
        "id": "vfqZkY92xNH5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}